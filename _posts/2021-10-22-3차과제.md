# 6 The universal workflow of machine learning

우리는 이전에 우리가 이미 전처리된 데이터세트를 가지고 있고 그것으로부터 즉시 모델 훈련을 시작할 수 있다고 가정했다. 그러나 현실에서 이것은 흔치않다. 당신은 데이터세트에서가 아니라 문제점으로부터 시작할 것이다.

#### Note on ethics

기술은 결코 중립적이지 않다. 당신이 하는 일이 세상에 어떤 영향을 미친다면 도덕적 방향이어야 할 것 이다. 또한 기술적 선택은 윤리적 선택이기도 하다. 이는 우리의 작업이 지향하는 가치에 대해 항상 고민해야하는 이유이기도 하다.

## 6.1 Define the task

당신은 당신이 하려는 일에 대한 깊은 이해없이는 작업을 잘 수행할 수 없다. 고객이 왜 이 특정 문제를 해결하려고 하는지, 솔루션으로 얻을 수 있는 가치가 무엇인지, 모델이 어떻게 사용되는지, 그것이 고객의 작업 절차에 잘 맞는지, 어떤 데이터가 유용하고 정확한지, 어떤 머신러닝 작업이 문제 해결에 적절한지 파악해야 한다.

### 6.1.1 Frame the problem
머신러닝 문제를 정의하기 위해서 섬세한 고민들이 필요하다.

 몇가지 질문을 던져볼 수 있다.
  
   * 당신의 입력 데이터는 무엇이며, 무엇을 예측하고자 하는가?

   >당신은 사용 가능한 훈련 데이터가 있는 경우에만 무언가를 예측하는 방법을 배울 수 있다.
 
   * 어떤 유형의 머신러닝 작업에 직면하고 있는가?

   >어떤 경우에는 머신러닝이 데이터를 이해하는 가장 좋은 방법이 아닐 수 있으며, 단순한 통계분석과 같은 다른 것을 사용해야 할 수도 있다.
 
   * 기존 솔루션은 어떻게 생겼는가?

   >어떤 시스템이 이미 설치되어 있고 어떻게 작동하는지 확실히 이해해야 한다.
 
   * 처리해야 하는 특정 제약 조건이 있는가?

   >당신은 당신의 작업이 적합하도록 전체의 맥락을 이해해야 한다.
 
 조사를 마치고나면 광범위한 유형의 머신러닝 작업을 알아야 한다. 이 단계에서는 다음 가설을 주의해야 한다.
 
   * 입력이 주어지면 타깃을 예측할 수 있다는 가정
 
   * 사용 가능한 데이터가 입력과 타깃 간의 관계를 학습하기에 충분히 유용하다는 가정
 
머신러닝으로 모든 문제를 해결할 수 있는 것은 아니며 수집한 데이터가 반드시 예측에 충분한 것은 아니기 때문에 주의해야한다.

### 6.1.2. Collect a dataset

작업을 이해하고 입력과 대상이 무엇인지 알게되면 데이터 수집을 할 때이다. 대부분의 머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 부분이다.

모델의 일반화 능력은 전적으로 모델이 보유한 데이터 수, 레이블의 신뢰성, 기능의 품질에 대해 훈련된 데이터의 속성에서 비롯된다.

딥러닝의 부상으로 데이터의 중요성은 커지고 있다.

지도학습을 수행하는 경우 입력을 수집하면 해당 입력에 대한 주석(모델을 학습하여 예측할 대상)이 필요하다.

데이터 주석 프로세스는 대상의 품질을 결정하고 이는 차례로 모델의 품질을 결정한다. 사용 가능한 옵션을 신중하게 고려하여 투자해야 한다.

최상의 옵션을 선택하려면 작업 중인 제약 조건을 고려해야한다.

   * data labeler가 주제에 대한 전문가가 되어야하는가 아니면 데이터에 주석을 달 수 있는 사람이 있는가

   * 데이터에 주석을 추가하는 데 전문지식이 필요한 경우 관련 교육을 할 수 있는가, 그렇지 않다면 관련 전문가에게 접근할 수 있는가

   * 전문가가 주석을 작성하는 방식을 이해하고 있는가

내부에서 데이터에 레이블을 지정하기로 결정했다면 주석을 기록하는 데 어떤 소프트웨어를 사용할 것인지 생각해보아야 한다. 해당 소프트웨어를 직접 개발해야 할 수도 있다.

생산적인 데이터는 많을 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있다.

#### 대표성이 없는 데이터에 주의

머신러닝 모델은 이전에 본 것과 유사한 입력만 이해할 수 있다. 따라서 훈련에 사용되는 데이터는 생산데이터를 대표해야 하며 이 문제는 모든 데이터 수집 작업의 기초가 된다.

가능하면 모델이 사용될 환경에서 직접 데이터를 수집하는 것이 좋다. 생산 데이터에 대해 학습할 수 없는 경우에는 훈련데이터와 생산 데이터가 어떻게 다른지 이해하고 차이점을 적극적으로 수정하고 있는지 확인해야 한다.

관련하여 concept drift에 대해 알고 있어야 한다. 사용자가 생산 데이터를 다루는 문제에서 발생하는데 생산 데이터의 속성이 시간이 지남에 따라 변경되어 모델 정확도가 점차 저하될 때 발생한다.

머신러닝은 훈련데이터에 있는 패턴을 기억하는 데만 사용할 수 있다는 점을 기억해야한다. 과거 데이터에 대해 훈련된 머신러닝을 사용하여 미래를 예측하는 것은 정확하지 않은 경우가 많다.

#### Note:The problem of sanpling bias

데이터에 대표성이 없는 경우는 샘플링 편향이다. 샘플링 편향은 데이터 수집 프로세스가 예측하려는 대상과 상호작용하여 편향된 측정이 발생할 때 발생한다.

### 6.1.3 Understand your data

모델 훈련을 시작하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고 기능 엔지니어링에 정보를 제공하고 잠재적인 문제를 선별해야한다.

데이터에 이미지나 자연어 텍스트가 포함된 경우 몇 가지 샘플을 직접 살펴보고, 데이터에 수치적 특성이 포함된 경우 특성 값의 히스토그램을 그려서 취한값의 범위와 다른 값의 빈도를 파악하는 것이 좋다.

위치 정보가 포함된 경우 지도에 표시한다. 

일부 샘플에서 일부 기능의 값이 누락되었다면 이 문제도 처리해야 한다.

작업이 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 프린트해야하고 클래스가 동등하게 표현되는지 확인해야 한다.

또한 프로덕선에서 사용할 수 없는 대상에 대한 정보를 제공하는 데이터의 기능이 잇는지 확인한다.

#### Choose a measure of success

무언가를 통제하려면 관찰할 수 있어야 한다. 프로젝트에서 성공하려면 먼저 성공 정확도가 무엇을 의미하는지 정의해야 한다. 정밀도나 재현율 등 성공을 위한 지표는 프로젝트 전반에 걸쳐 당신이 내릴 모든 기술적 선택의 기준이 된다.

또한 성공을 측정하는 데 사용할 사용자 지정 metric을 정의해야 하는 경우가 많다. 머신 러닝 성공 지표의 다양성과 다양한 문제 영역과의 관계를 이해하려면 Kaggle에서 데이터 과학 경시 대회를 검색하는 것이 좋다.

## 6.2 Develop a model

진행 상황을 측정하는 방법을 알고나면 모델 개발을 시작할 수 있다.

### 6.2.1 Prepare the data

딥러닝 모델은 일반적으로 데이터를 수집하지 않는다. 데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 한다. 여기에는 벡터화, 정규화 또는 누락된 값 처리가 포함된다. 많은 전처리 기술은 도메인에 따라 다르다. 

#### 벡터화

신경망의 모든 입력 및 타깃은 일반적으로 부동 소수점 데이터의 텐서여야 한다. 데이터가 무엇이든 먼저 벡터화를 통해 텐서로 변환해야 한다. 에를 들어 앞에서 원핫인코딩을 사용한 것을 확인할 수 있다.

#### Value 정규화

데이터를 네트워크에 제공하기 전에 각 기능을 독립적으로 정규화하여 표준 편차가 1이고, 평균이 0이 되도록 한다.
 
 일반적으로 상대적으로 큰 값을 가져오는 데이터나 이질적인 데이터를 신경망에 공급하는 것은 안전하지 않다.
 
 그렇게 하면 네트워크 수렴을 방지하는 대규모 그레이디언트 업데이트가 trigger될 수 있다. 네트워크에서 더 쉽게 학습할 수 있도록 데이터에는 다음과 같은 특성이 있어야한다.
 
   * Take small values : 일반적으로 대부분의 값은 0과1 사이에 있어야 한다.
 
   * Be homogenous : 모든 기능은 거의 동일한 범위의 값을 취해아 한다.
 
 또한 다음과 같은 보다 엄격한 정규화 방식이 일반적이며 항상 필요한 것은 아니지만 도움이 될 수 있다.
 
   * 평균이 0이 되도록 각 특성을 독립적으로 정규화한다.
 
   * 표준편차가 1이 되도록 각 특성을 독립적으로 정규화한다.
 
때때로 데이터에 누락된 값이 있을 수 있다. 어떠한 기능이 모든 샘플에서 사용되는 것은 아닙니다. 이 기능을 완전히 버릴 수도 있지만 반드시 그럴 필요는 없다.

   * 기능이 범주형인 경우 : '값이 누락됨'을 의미하는 새 범주를 생성하는 것이 안전하다.

   * 특성이 숫자인 경우 : '0'같은 임의의 값을 입력하지 말고 데이터세트이 기능에 대한 평균 또는 중앙값으로 박는 것이 좋다. 다른 특성 값이 주어지면 특성 값을 예측하도록 모델을 훈련시킬 수도 있다.

테스트 데이터에서 누락된 범주 기능이 예상되지만 누락된 값이 없는 데이터에 대해 네트워크가 학습된 경우 네트워크는 누락된 값을 무시하는 방법을 학습하지 못할 것이다. 이 상황에서는 누락된 항목이 잇는 훈련 샘플을 인위적으로 생성해야 한다. 일부 훈련 샘플을 여러번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 기능 중 일부는 삭제한다.

### 6.2.2 Choose an evaluation prtocol
 
모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반 걸쳐 내리는 모든 결정은 일반화 성능을 측정하려는 검증 metric에 따라 결정된다. 검증 프로토콜의 목표는 실제 생산 데이터에서 선택한 성공 metric를 정확하게 추정하는 것이다. 이 프로세스의 신뢰성은 유용한 모델을 구축하는데 매우 중요하다.

   * 일반적인 평가 프로토콜

     * 홀드아웃 검증 세트 유지 : 데이터가 많을 때

     * k-fold 교차 검증 수행 : 신뢰할 수 있는 홀드아웃 검증을 위한 샘플이 너무 적을 때

     * 반복된 K-검증 수행 : 사용 가능한 데이터가 거의 없을 때

이 중 하나를 선택하면 대부분의 경우 작업이 잘 작동한다. 항상 검증 세트의 대표성을 염두에 두고 훈련 세트와 검증 세트 사이에 중복 샘플이 없도록 주의해야한다.

### 6.2.3 Beat a baseline

모델 자체에 대한 작업을 시작할 때 초기 목효는 통계적 검정을 달성하는 것이다. 이 단계에서는 세가지에 중점을 두어야한다.

   * 기능 엔지니어링 : 정보가 없는 기능을 걸러내고 문제에 대한 지식을 사용하여 유용할 가능성이 있는 새로운 기능을 개발

   * 올바른 아키텍처 사전 선택 : 어떤 유형의 모델 아키텍처를 사용할 것인가? 

   * 좋은 훈련 구성 선택 : 어떤 손실 함수를 사용해야 하는가? 배치 크기와 학습률은 얼마인가?

#### Note: 올바른 손실 함수 선택

문제의 성공을 측정하는 metric에 대한 최적화가 어려울 때는 metric를 손실 함수로 바꿀 수도 있다. 손실 함수는 결국 데이터의 미니 배치만 주어지면 계산 가능해야 하고 미분 가능해야 한다.

대부분의 문제는 기존의 모델이 있기에 작업을 잘 수행할 가능성이 가장 높은 기능 및 모델 아키텍쳐를 찾기 위해 선행 기술을 조사해야 한다.

### 6.2.4 Scale up : develop a model that overfits

머신러닝의 성능은 최적화와 일반화 사이에 있다. 이상적인 모델은 과소적합과 과대적합의 경계에 있는 모델이다. 

모델의 크기를 파악하려면 과대적합되는 모델을 개발해야 한다. 

 1. 레이어 추가

 2. 레이어를 더 크게 만든다.

 3. 더 많은 에포크를 훈련.

훈련 손실 및 검증 손실은 물론 모든 지표에 대한 훈련 및 검증 값을 모니터링 해야한다. 검증 데이터에 대한 모델의 성능이 저하되기 시작하는 것이 보이면 과대적합이 생긴 것이다.

### 6.2.5 Regularize and tune your model

통계적 검정력을 달성하고 과적합할 수 있게 되면 올바른 길을 가고 있다는 것이다.

이 시점에서의 목표는 일반화 성을 최대화하는 것이다.

이 단계는 시간이 오래 걸린다. 모델이 좋아질 때까지 가능한한 반복적으로 수정하고, 훈련하고, 데이터의 유효성을 평가하는 과정을 반복해야 한다.

다음은 시도해야 할 몇가지 사항이다.

   * 탈락 추가.
   * 모델이 작은 경우 L1 또는 L2 정규화 추가.
   * 최적의 구성을 찾기 위해 다른 하이퍼파라미터를 시도.
   * 선택적으로 데이터 큐레이션 또는 기능 엔지니어링을 반복. 더 많은 데이터를 수집 및 주석 처리하거나, 더 나은 기능을 개발하거나, 유익하지 않은 기능을 제거.

검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모델에 노출된다. 반복을 통해 지속적으로 수행되면 결국 모델이 과대적합되고 이로 인해 신뢰성이 떨어진다.

만족스러운 모델 구성을 개발했으면 사용 가능한 모든 데이터에 대해 최종 모델을 훈련하고 테스트 세트에서 마지막으로 평가할 수 있다. 테스트 세트의 성능이 유효성 검사 데이터에서 측정된 성능보다 훨씬 더 나쁜 것으로 판명되면 유효성 검사 절차가 결국 신뢰할 수 없거나 매개변수를 조정하는 동안 과대적합 되었음을 의미할 수 있다.

## 6.3 Deploy your model

모델이 테스트 세트에 대한 최종 평가를 통과했다.

### 6.3.1 Explain your work to stakeholders and set expetations

성공은 고객의 기대를 지속적으로 충족하는 것이다. 

AI 시스템에 대한 비전문가의 기대는 종종 비현실적이다. 하지만 머신러닝 모델은 인간이 생성한 레이블에 근접하도록 훈련되었기 때문에 사람 수준의 성능에 도달하지는 못한다. 따라서 모델 성능 기대치를 명확하게 전달해야 한다.

또한 거래에 플래그를 지정해야 하는 확률 임계값과 같은 주요 시작 매개변수의 선택에 대해 이해 관계자와 논의해야 한다. 이러한 결정에는 비즈니스 컨텍스트에 대한 깊은 이해가 있어야만 한다.

### 6.3.2 Ship an inference model

머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 코랩 노트북에 저장했다고 해서 끝나지 않는다.

모델을 파이썬이 아닌 다른 것으로 내보낼 수도 있다.

   * 모바일 앱이나 임베디드 시스템의 환경에서 파이썬을 전혀 지원하지 않을 수 있다.

   * 앱의 나머지 부분이 파이썬이 아닌 경우 파이썬 모델을 제공하면 많은 오버헤드가 발생할 수 있다.

또한 프로덕션 모델은 학습이 아닌 예측을 출력하는 데만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 최적화의 여지가 있다.

사용 가능한 다양한 모델 배포 옵션을 살펴보자.

   * 모델을 REST API로 배포

      * 모델의 예측을 소비할 애플리케이션은 인터넷에 안정적으로 액세스할 수 있다. 예를 들어 애플리케이션이 모바일 앱인 경우 원격 API에서 예측을 제공하면 비행기 모드나 연결성이 낮은 환경에서 애플리케이션을 사용할 수 없다.

     * 응용 프로그램에는 엄격한 대기 시간 요구 사항이 없다.

     * 입력을 위해 전송된 입력 데이터는 매우 민감하지 않다. 데이터는 모델에서 볼 수 있어야 하므로 서버에서 암호 해독된 형식으로 사용할 수 있어야 한다.

   * 기기에 모델 배포

      * 모델에 엄격한 대기 시간 제약이 있거나 낮은 연결 환경에서 실행해야 한다. 몰입형 증강 현실 애플리케이션을 구축하는 경우 원격 서버에 쿼리하는 것은 실행 가능한 옵션이 아니다.

     * 모델은 대상 장치의 메모리 및 전력 제약 조건에서 실행할 수 있을 정도로 충분히 작게 만들 수 있다.

     * 가능한 최고의 정확도를 얻는 것은 작업에 중요하지 않다. 런타임 효율성과 정확도 사이에는 항상 상충 관계가 있으므로 메모리 및 전력 제약으로 인해 종종 대형 GPU에서 실행할 수 있는 최고의 모델이다.

     * 입력 데이터는 매우 민감하므로 원격 서버에서 해독할 수 없다.

   * 브라우저에서 모델 배포

      * 서버 비용을 크게 줄일 수 있는 최종 사용자에게 컴퓨팅을 오프로드하려고 한다.

      * 입력 데이터는 최종 사용자의 컴퓨터 또는 전화에 남아 있어야 한다.

      * 응용 프로그램에는 엄격한 대기 시간 제약이 있다. 최종 사용자의 랩톱이나 스마트폰에서 실행되는 모델은 자체 서버의 대형 GPU에서 실행되는 모델보다 느릴 수 있지만 추가로 100ms의 네트워크 왕복이 없다.

      * 모델을 다운로드하고 캐시한 후 연결 없이 계속 작동하려면 앱이 필요하다.

#### Inference model optivization

추론을 위해 모델을 최적화하는 것은 사용 가능한 전력 및 메모리에 대한 엄격한 제약이 있는 환경 또는 대기 시간 요구사항이 짧은 애플리케이션에 배포할 때 특히 중요하다.

적용 가능한 두가지 최적화 기술이 있다.

   * 가중치 가지치기: 가중치 텐서의 모든 계수가 예측에 동일하게 기여하는 것은 아니다. 가장 중요한 매개변수만 유지하여 모델 레이어의 매개변수 수를 상당히 줄일 수 있다. 이렇게 하면 성능 메트릭에서 적은 비용으로 모델의 메모리 및 컴퓨팅 공간이 줄어든다. 적용하려는 가지치기의 양을 조정하여 크기와 정확도 사이의 균형을 제어할 수 있다.

   * 가중치 양자화: 딥 러닝 모델은 단정밀도 부동 소수점(float32) 가중치로 학습된다. 그러나 가중치를 8비트 부호 있는 정수(int8)로 양자화하여 4배 더 작지만 원래 모델의 정확도에 가깝게 유지되는 추론 전용 모델을 얻을 수 있다.

### 6.3.3 Monitor your model in the wild

추론 모델을 내보내고 애플리케이션에 통합했으며 생산 데이터에 대한 테스트 실행을 완료했다. 이제 프로덕션에 배포할 차례이다.

모델을 배포한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호작용 및 최종 영향을 계속 모니터링 해야한다.

### 6.3.4 Maintain your model

마지막으로 영원히 지속되는 모델은 없다. 시간이 지남에 따라 생산 데이터의 특성이 변경되어 모델의 성능과 관련성이 점차 저하된다.

모델이 출시되자마자 다음과 같이 대체할 차세대를 훈련할 준비를 해야한다.

   * 생산 데이터의 변경에 주의한다. 새로운 기능을 사용할 수 있는가? 레이블 세트를 확장하거나 편집해야 하는가?

   * 계속해서 데이터를 수집하고 주석을 달고 시간이 지남에 따라 주석 파이프라인을 계속 개선한다. 특히 현재 모델에 대해 분류하기 어려운 것처럼 보이는 샘플을 수집하는 데 특별한 주의를 기울여야 한다. 이러한 샘플은 성능 향상에 가장 도움이 된다.

이것으로 머신러닝의 보편적인 작업순서가 끝났다. 

## 6.4 Chapter summary

   1. 새로운 기게학습 프로젝트를 맡을 때 먼저 당면한 문제를 정의해라.

       * 당신이 하려고 하는 것의 더 넓은 맥락을 이해해야한다. 최종 목표는 무엇이며 제약 조건은 무엇인가?

       * 데이터세트를 수집하고 주석을 단다. 데이터를 깊이 있게 이해해야 한다.

       * 문제에 대한 성공을 측정하는 방법을 선택한다. 검증 데이터에서 어떤 metric을 모니터링 하는가?

   2. 문제를 이해하고 적절한 데이터 세트가 있으면 모델을 개발해라.

       * 데이터를 준비한다.

       * 평가 프로토콜을 선택한다.

       * 과대적합이 가능한 모델을 개발한다.

       * 검증 데이터의 성능을 기반으로 모델을 정규화하고 하이퍼파라미터를 조정한다.
       
   3. 배포를 준비해라.

        * 적절한 기대치를 설정한다.

        * 모델을 최적화하고 배포 환경에 모델을 배포한다.

        * 모델의 성능을 모니터링하고 차세대 모델 개발을 준비한다. 
