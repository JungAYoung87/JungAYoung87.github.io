# Tensor 소개

## 기초

텐서는 일종의 **np.array**와 같은 다차원 배열이다.

텐서의 종류를 살펴보면 먼저 rank-0 텐서, 스칼라가 있다.
스칼라는 축이 없고 단일값만 포함한다.

```python
# This will be an int32 tensor by default; see "dtypes" below.
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
```

```
tf.Tensor(4, shape=(), dtype=int32)
```

두 번째 rank-1 텐서, 벡터는 값의 리스트로, 하나의 축을 갖는다.

```python
# Let's make this a float tensor.
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
```

```
tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
```

다음으로 rank-2 텐서, 행렬은 두개의 축을 갖는다.

```python
# If you want to be specific, you can set the dtype (see below) at creation time
rank_2_tensor = tf.constant([[1, 2],
                             [3, 4],
                             [5, 6]], dtype=tf.float16)
print(rank_2_tensor)
```

```
tf.Tensor(
[[1. 2.]
 [3. 4.]
 [5. 6.]], shape=(3, 2), dtype=float16)
```

따라서 앞의 3가지 텐서는 아래와 같은 방식으로 이해할 수 있다.

![](https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/docs/assets/images/tensor.JPG?raw=true)

하지만 rank-2보다 많은 축을 갖는 텐서도 존재할 수 있다.

```python
# There can be an arbitrary number of
# axes (sometimes called "dimensions")
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor)
```

```
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```

축을 3개 이상 갖는 텐서들을 시각화하면 다음과 같이 이해할 수 있다.

<img src="https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/assets/1.JPG?raw=true" width="310"> <img src="https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/assets/2.JPG?raw=true" width="310"> <img src="https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/assets/3.JPG?raw=true" width="310">

출처: <https://www.youtube.com/watch?v=m0qwxNA7IzI>  
     
           
     
**np.array** 또는 **tensor.numpy** 메서드를 사용하여 텐서를 NumPy 배열로 변환할 수 있다.

```python
np.array(rank_2_tensor)
```

```
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```

```python
rank_2_tensor.numpy()
```

```
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```

텐서에는 주로 float 와 int가 포함되지만 복소수나 string을 포함하는 경우도 있다.

기본 **tf.Tensor** 클래스에서는 각 축의 모든 요소의 크기가 같은 직사각형이어야 하지만 다양한 형상을 처리하기 위한 특수 유형의 텐서도 있다.

* 비정형 텐서

* 희소 텐서

텐서에 대해 덧셈, 곱셈, 행렬곱 등을 포함한 기본 산술을 수행할 수 있다.

```python
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]]) # Could have also said `tf.ones([2,2])`

print(tf.add(a, b), "\n")
print(tf.multiply(a, b), "\n")
print(tf.matmul(a, b), "\n")
```

```
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32)
```

```python
print(a + b, "\n") # element-wise addition
print(a * b, "\n") # element-wise multiplication
print(a @ b, "\n") # matrix multiplication
```

```
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32)
```

텐서는 모든 종류의 연산에 사용된다.

```python
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# Find the largest value
print(tf.reduce_max(c))
# Find the index of the largest value
print(tf.argmax(c))
# Compute the softmax
print(tf.nn.softmax(c))
```

```
tf.Tensor(10.0, shape=(), dtype=float32)
tf.Tensor([1 0], shape=(2,), dtype=int64)
tf.Tensor(
[[2.6894143e-01 7.3105854e-01]
 [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)
```

***

## shapes

* 용어정리
  * shape : 텐서의 각 차원의 길이(요소의 수)
  * rank : 텐서 축의 수
  * 축 또는 차원 : 텐서의 특정 차원
  * size : 텐서의 총 항목 수

텐서 및 **tf.TensorShape** 객체에는 엑세스하는 데에 다음과 같은 편리함이 있다.

```python
rank_4_tensor = tf.zeros([3, 2, 4, 5])
```

![](https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/assets/4.JPG?raw=true)

```python
print("Type of every element:", rank_4_tensor.dtype)
print("Number of axes:", rank_4_tensor.ndim)
print("Shape of tensor:", rank_4_tensor.shape)
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0])
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1])
print("Total number of elements (3*2*4*5): ", tf.size(rank_4_tensor).numpy())
```

```
Type of every element: <dtype: 'float32'>
Number of axes: 4
Shape of tensor: (3, 2, 4, 5)
Elements along axis 0 of tensor: 3
Elements along the last axis of tensor: 5
Total number of elements (3*2*4*5):  120
```

일반적인 축의 순서로는 배치 축이 먼저 오고 그 다음에 공간 차원과 각 위치 특성이 마지막에 온다.

***

## Indexing

### 단일축 indexing

* 기본 규칙
  * 인덱스는 0에서 시작
  * 음수 인덱스는 끝에서부터 거꾸로 계산
  * 콜론, :은 start: stop: 에서 사용

```python
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())
```

```
[ 0  1  1  2  3  5  8 13 21 34]
```

스칼라를 사용하여 인덱싱하면 축이 제거된다.

```python
print("First:", rank_1_tensor[0].numpy())
print("Second:", rank_1_tensor[1].numpy())
print("Last:", rank_1_tensor[-1].numpy())
```

```
First: 0
Second: 1
Last: 34
```

:를 사용하여 인덱싱하면 축이 유지된다.

```python
print("Everything:", rank_1_tensor[:].numpy())
print("Before 4:", rank_1_tensor[:4].numpy())
print("From 4 to the end:", rank_1_tensor[4:].numpy())
print("From 2, before 7:", rank_1_tensor[2:7].numpy())
print("Every other item:", rank_1_tensor[::2].numpy())
print("Reversed:", rank_1_tensor[::-1].numpy())
```

```
Everything: [ 0  1  1  2  3  5  8 13 21 34]
Before 4: [0 1 1 2]
From 4 to the end: [ 3  5  8 13 21 34]
From 2, before 7: [1 2 3 5 8]
Every other item: [ 0  1  3  8 21]
Reversed: [34 21 13  8  5  3  2  1  1  0]
```

### 다축 indexing

더 높은 rank의 텐서는 여러 인덱스를 전달하여 인덱싱된다.

단일 축의 경우에서와 걑은 규칙이 각 축에 적용된다.

```python
print(rank_2_tensor.numpy())
```

```
[[1. 2.]
 [3. 4.]
 [5. 6.]]
```

각 인덱스에 정수를 전달하면 결과는 스칼라가 나온다.

```python
# Pull out a single value from a 2-rank tensor
print(rank_2_tensor[1, 1].numpy())
```

```
4.0
```

정수와 :을 조합하여 인덱싱할 수 있다.

```python
# Get row and column tensors
print("Second row:", rank_2_tensor[1, :].numpy())
print("Second column:", rank_2_tensor[:, 1].numpy())
print("Last row:", rank_2_tensor[-1, :].numpy())
print("First item in last column:", rank_2_tensor[0, -1].numpy())
print("Skip the first row:")
print(rank_2_tensor[1:, :].numpy(), "\n")
```

```
Second row: [3. 4.]
Second column: [2. 4. 6.]
Last row: [5. 6.]
First item in last column: 2.0
Skip the first row:
[[3. 4.]
 [5. 6.]]
```

***

## Manipulating Shapes 형상 조작하기

텐서의 형상을 바꾸는 것은 유용하다.

```python
# Shape returns a `TensorShape` object that shows the size along each axis
x = tf.constant([[1], [2], [3]])
print(x.shape)
```

```
(3, 1)
```

텐서를 새로운 shape로 바꿀 수 있다. **tf.reshape**는 기본 데이터를 복제할 필요가 없어 재구성이 빠르고 저렴하다.

```python
# You can reshape a tensor to a new shape.
# Note that you're passing in a list
reshaped = tf.reshape(x, [1, 3])
```

```python
print(x.shape)
print(reshaped.shape)
```

```
(3, 1)
(1, 3)
```

데이터의 레이아웃은 메모리에서 그대로 유지되고 같은 데이터를 가지는 요청된 shape의 새 텐서가 작성된다.

텐서를 평평하게 하면 어떤 순서로 메모리에 배치되어 있는지도 확인할 수 있다.

일반적으로 **tf.reshape**의 용도는 인접한 축을 결합하거나 분할하는 것이다.

***

## DTypes에 대한 추가정보

**tf.Tensor**의 데이터 유형을 검사하려면 **Tensor.dtype**속성을 사용한다.

Python 객체에서 **tf.Tensor**를 만들 때 선택적으로 데이터 유형을 지정하지 않으면 TensorFlow는 정수를**tf.int32**로, 부동 소수점 숫자를 **tf.float32**로 변환한다.

***

## Broadcasting

Broadcasting은 특정 조건에서 작은 텐서는 결합된 연산을 실행할 때 더 큰 텐서에 맞게 자동으로 행과 열이 확장되는 것을 의미한다.

가장 간단한 경우는 스칼라에 텐서를 고바거나 추가하려고 하는 경우로 이 경우 스칼라는 다른 인수와 같은 셩상으로 broadcast된다.


```python
x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])
# All of these are the same computation
print(tf.multiply(x, 2))
print(x * y)
print(x * z)
```

```
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
```

마찬가지로, 크기가 1인 축은 다른 인수와 일치하도록 확장할 수 있다.

![](https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/assets/%EB%B8%8C%EB%A1%9C%EB%93%9C%EC%BA%90%EC%8A%A4%ED%8A%B8.JPG?raw=true)

대부분의 경우 broadcasting은 메모리에서 확장된 텐서를 구체화하지 않으므로 시간과 공간 효율적이다.

**tf.broadcast_to**를 사용하여 broadcasting이 어떤 모습인지 확인할 수 있다.

```python
print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))
```

```
tf.Tensor(
[[1 2 3]
 [1 2 3]
 [1 2 3]], shape=(3, 3), dtype=int32)
```

***

## tf.convert_to_tensor

대부분의 ops는 텐서가 아닌 인수에 대해 **convert_to_tensor**를 호출한다. 변환 레지스트리가 있어 Numpy의 **ndarray**, **TensorShape**, Python 목록 및 **tf.Variable**과 같은 대부분의 객체 클래스는 모두 자동으로 변환된다.

***

## 비정형 텐서

어떤 축을 따라 다양한 수의 요소를 가진 텐서를 비정형이라고 한다. 

비정형 데이터에는 **tf.ragged.RaggedTensor**를 사용한다.

예를 들어 비정형 텐서는 정규텐서로 표현할 수 없다.

```python
ragged_list = [
    [0, 1, 2, 3],
    [4, 5],
    [6, 7, 8],
    [9]]
```

```python
try:
  tensor = tf.constant(ragged_list)
except Exception as e:
  print(f"{type(e).__name__}: {e}")
```

```
ValueError: Can't convert non-rectangular Python sequence to Tensor.
```

대신 **tf.ragged.constant**를 사용하여 **tf.RaggedTensor**를 작성한다.

```python
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)
```

```
<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>
```

***

## 문자열 텐서

**tf.string**은 텐서에서 문자열과 같은 데이터를 나타낼 수 있는**dtype**이다.

문자열의 길이는 텐서의 축 중의 하나가 아니다.

스칼라 문자열 텐서는 다음과 같다.

```python
# Tensors can be strings, too here is a scalar string.
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)
```

```
tf.Tensor(b'Gray wolf', shape=(), dtype=string)
```

벡터는 다음과 같다.

![](https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/assets/string.JPG?raw=true)

문자열이 있는 일부 기본 함수는 **tf.strings**을 포함하여 **tf.strings.spilt**에서 찾을 수 있다.

또한 **tf.cast**를 사용하여 문자열 텐서를 숫자로 변환할 수는 없지만, 바이트로 변환한 다음 숫자로 변환할 수 있다.

***

## 희소 텐서

TensorFlow는 **tf.sparse.SparseTensor**를 지원하여 희소 데이터를 효율적으로 저장한다.

![](https://github.com/JungAYoung87/JungAYoung87.github.io/blob/master/assets/sparse.JPG?raw=true)

```python
# Sparse tensors store values by index in a memory-efficient manner
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")

# We can convert sparse tensors to dense
print(tf.sparse.to_dense(sparse_tensor))
```

```
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 

tf.Tensor(
[[1 0 0 0]
 [0 0 2 0]
 [0 0 0 0]], shape=(3, 4), dtype=int32) 
```



